from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import (NoSuchElementException, TimeoutException,
                                        ElementClickInterceptedException)
import csv
import time
import random


# å·¥å…·å‡½æ•°ï¼šéšæœºå»¶è¿Ÿï¼ˆæå–é€šç”¨é€»è¾‘ï¼‰
def random_delay(min_sec=0.2, max_sec=1):
    time.sleep(random.uniform(min_sec, max_sec))


# 1. åˆå§‹åŒ–æµè§ˆå™¨é©±åŠ¨ï¼ˆç²¾ç®€é…ç½®é¡¹ï¼Œä¿ç•™æ ¸å¿ƒåçˆ¬è®¾ç½®ï¼‰
def init_driver():
    chrome_options = Options()
    chrome_options.add_argument("--headless=new")  # æ— å¤´æ¨¡å¼
    chrome_options.add_argument("--disable-extensions")  # ç¦ç”¨æ‰©å±•
    chrome_options.add_argument("--disable-plugins")  # ç¦ç”¨æ’ä»¶
    chrome_options.add_argument("--no-sandbox")  # ç¦ç”¨æ²™ç›’ï¼ˆLinuxç¯å¢ƒå¿…è¦ï¼ŒWindowså¯é€‰ï¼‰
    chrome_options.add_argument("--disable-gpu")  # ç¦ç”¨GPUåŠ é€Ÿï¼ˆæ— å¤´æ¨¡å¼æ— éœ€ï¼‰
    chrome_options.page_load_strategy = 'eager'
    chrome_options.add_argument("--disable-popup-blocking")
    chrome_options.add_argument("--window-size=1920,1080")
    chrome_options.add_argument(
        "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"
    )
    # æ€§èƒ½ä¼˜åŒ–ï¼šç¦ç”¨ä¸å¿…è¦èµ„æºåŠ è½½
    chrome_options.add_argument("--blink-settings=imagesEnabled=false")
    # æ‹¦æˆªå›¾ç‰‡ã€CSSã€JSï¼ˆæ›´å½»åº•çš„èµ„æºç¦ç”¨ï¼‰
    prefs = {
        "profile.managed_default_content_settings.images": 2,  # ç¦ç”¨å›¾ç‰‡
        "profile.managed_default_content_settings.stylesheets": 2,  # ç¦ç”¨CSS
        "javascript.enabled": False  # ç¦ç”¨JSï¼ˆè‹¥é¡µé¢æ•°æ®ä¸ä¾èµ–JSæ¸²æŸ“åˆ™å¯ç”¨ï¼‰
    }
    chrome_options.add_experimental_option("prefs", prefs)
    # åçˆ¬æ ¸å¿ƒé…ç½®
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option("useAutomationExtension", False)

    try:
        driver = webdriver.Chrome(options=chrome_options)
        # æ¸…é™¤webdriveræ ‡è®°
        driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
            "source": "Object.defineProperty(navigator, 'webdriver', {get: () => undefined})"
        })
        return driver
    except Exception as e:
        print(f"æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        return None


# 2. æå–å•é¡µèœå“ä¿¡æ¯ï¼ˆç®€åŒ–é€»è¾‘ï¼Œåˆå¹¶å¼‚å¸¸å¤„ç†ï¼‰
def extract_single_page(driver, page_num):
    try:
        # ç­‰å¾…é¡µé¢åŠ è½½
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.TAG_NAME, "tbody"))
        )
        random_delay()

        # æå–é¡µé¢æ–‡æœ¬å¹¶å¤„ç†
        lines = [line.strip() for line in driver.find_element(By.TAG_NAME, "body").text.split('\n')
                 if line.strip()]
        if not lines:
            print(f"ç¬¬{page_num}é¡µæ— æœ‰æ•ˆå†…å®¹")
            return []

        # æå–åç§°åˆ—è¡¨
        name_marker = "Name"
        if name_marker not in lines:
            print(f"ç¬¬{page_num}é¡µæœªæ‰¾åˆ°Nameæ ‡è®°")
            return []

        name_start = lines.index(name_marker) + 1
        name_end = lines.index("0: ä¼°è®¡0å€¼ï¼Œç†è®ºä¸Šä¸º0å€¼æˆ–ä¸å­˜åœ¨ï¼Œæˆ–æµ‹å®šåä¸º0")
        name_list = lines[name_start:name_end]

        # æå–æ•°æ®åˆ—è¡¨
        try:
            data_start = lines.index("Major") + 1
            data_end = lines.index(name_marker)
            data_list = lines[data_start:data_end]
        except ValueError:
            print(f"ç¬¬{page_num}é¡µæ•°æ®æ ‡è®°å¼‚å¸¸")
            return []

        # æ•°æ®åŒ¹é…ï¼ˆå–æœ€å°åŒ¹é…é‡ï¼‰
        match_count = min(len(name_list), len(data_list) // 3)
        if match_count == 0:
            print(f"âš ï¸  ç¬¬{page_num}é¡µæ— åŒ¹é…æ•°æ®")
            return []

        # ç»„è£…æ•°æ®
        return [{
            "æ€»åºå·": (page_num - 1) * 10 + i + 1,
            "é¡µç ": page_num,
            "åç§°": name_list[i],
            "èƒ½é‡": data_list[3 * i],
            "åˆ†ç±»": data_list[3 * i + 1],
            "é…æ–™": data_list[3 * i + 2]
        } for i in range(match_count)]

    except Exception as e:
        print(f"ç¬¬{page_num}é¡µæå–å¼‚å¸¸: {str(e)[:50]}")
        return []


# 3. åˆ†é¡µçˆ¬å–æ ¸å¿ƒé€»è¾‘ï¼ˆç®€åŒ–åˆ†é¡µè·³è½¬ï¼Œåˆå¹¶é‡å¤åˆ¤æ–­ï¼‰
def crawl_all_pages(driver, start_page, max_page, batch_size=5):
    all_dishes = []  # å­˜å‚¨æ‰€æœ‰æ•°æ®
    current_batch = []  # å­˜å‚¨å½“å‰æ‰¹æ¬¡æ•°æ®
    batch_number = 1  # æ‰¹æ¬¡ç¼–å·
    current_page = start_page
    target_url = "https://nutridata.cn/database/list?id=2"

    try:
        driver.get(target_url)
        print(f"ğŸš€ å¼€å§‹ä»ç¬¬{start_page}é¡µçˆ¬å–ï¼Œå…±{max_page}é¡µï¼Œæ¯æ‰¹{batch_size}é¡µ")

        while current_page <= max_page:
            # æå–å½“å‰é¡µæ•°æ®
            page_data = extract_single_page(driver, current_page)
            if page_data:
                all_dishes.extend(page_data)
                current_batch.extend(page_data)
                print(f"âœ… ç¬¬{current_page}é¡µæå–æˆåŠŸ: {len(page_data)} æ¡èœå“")

                # å½“è¾¾åˆ°æ‰¹æ¬¡å¤§å°æˆ–æœ€åä¸€é¡µæ—¶ï¼Œä¿å­˜æ‰¹æ¬¡æ•°æ®
                if len(current_batch) >= batch_size * 10 or current_page == max_page:
                    # ä¿å­˜å½“å‰æ‰¹æ¬¡åˆ°ç‹¬ç«‹æ–‡ä»¶
                    batch_filename = f"æ‰¹æ¬¡{batch_number}.csv"
                    save_batch_data(current_batch, batch_filename)

                    # åŒæ—¶é™„åŠ åˆ°æ€»æ–‡ä»¶
                    save_matched_data(current_batch, "èœå“ä¿¡æ¯.csv", mode='a')

                    print(f"ğŸ’¾ æ‰¹æ¬¡{batch_number}ä¿å­˜å®Œæˆï¼Œæ–‡ä»¶: {batch_filename}")
                    print(f"ğŸ’¾ å·²å°†æ‰¹æ¬¡{batch_number}é™„åŠ åˆ°æ€»æ–‡ä»¶ï¼Œç´¯è®¡{len(all_dishes)}æ¡")

                    # é‡ç½®å½“å‰æ‰¹æ¬¡å¹¶é€’å¢æ‰¹æ¬¡ç¼–å·
                    current_batch = []
                    batch_number += 1

            # è·³è½¬ä¸‹ä¸€é¡µ
            if current_page < max_page:
                if not navigate_next_page(driver, current_page):
                    break  # è·³è½¬å¤±è´¥åˆ™ç»ˆæ­¢
            current_page += 1
            random_delay()

    except Exception as e:
        print(f"âŒ çˆ¬å–ä¸­æ–­: {e}")
    finally:
        # å¤„ç†å¯èƒ½å‰©ä½™çš„æœªå®Œæˆæ‰¹æ¬¡
        if current_batch:
            batch_filename = f"æ‰¹æ¬¡{batch_number}.csv"
            save_batch_data(current_batch, batch_filename)
            save_matched_data(current_batch, "æ€»æ•°æ®_æ‰€æœ‰èœå“ä¿¡æ¯.csv", mode='a')
            print(f"ğŸ’¾ æœ€åæ‰¹æ¬¡{batch_number}ä¿å­˜å®Œæˆï¼Œæ–‡ä»¶: {batch_filename}")

        print(f"ğŸ‰ çˆ¬å–å®Œæˆï¼å…±æå–{len(all_dishes)}æ¡èœå“ä¿¡æ¯")
        print(f"ğŸ“ æ€»æ•°æ®æ–‡ä»¶ï¼šæ€»æ•°æ®_æ‰€æœ‰èœå“ä¿¡æ¯.csv")
        return all_dishes

# è¾…åŠ©å‡½æ•°ï¼šä¿å­˜æ‰¹æ¬¡æ•°æ®ï¼ˆå¸¦è¡¨å¤´ï¼‰
def save_batch_data(batch_data, filename):
    if not batch_data:
        return

    headers = ["æ€»åºå·", "é¡µç ", "åç§°", "èƒ½é‡", "åˆ†ç±»", "é…æ–™"]
    with open(filename, 'w', encoding='utf-8-sig', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=headers)
        writer.writeheader()
        writer.writerows(batch_data)

# è¾…åŠ©å‡½æ•°ï¼šå¤„ç†ä¸‹ä¸€é¡µè·³è½¬ï¼ˆåˆ†ç¦»å…³æ³¨ç‚¹ï¼‰
def navigate_next_page(driver, current_page):
    try:
        # å°è¯•ç‚¹å‡»ä¸‹ä¸€é¡µæŒ‰é’®
        next_btn = WebDriverWait(driver, 10).until(
            EC.element_to_be_clickable((By.CSS_SELECTOR, "button.btn-next"))
        )

        if "disabled" in next_btn.get_attribute("class"):
            print(f"ğŸ”š ç¬¬{current_page}é¡µå·²æ˜¯æœ€åä¸€é¡µ")
            return False

        driver.execute_script("arguments[0].click();", next_btn)
        WebDriverWait(driver, 10).until(
            lambda d: str(current_page + 1) in d.page_source
        )
        return True

    except Exception as e:
        print(f"âŒ é¡µç è·³è½¬å¤±è´¥: {e}")
        return False


# 4. æ•°æ®ä¿å­˜ï¼ˆç²¾ç®€å‚æ•°å¤„ç†ï¼‰
def save_matched_data(dish_list, filename="æ€»æ•°æ®_æ‰€æœ‰èœå“ä¿¡æ¯.csv", mode='a'):
    if not dish_list:
        return

    headers = ["æ€»åºå·", "é¡µç ", "åç§°", "èƒ½é‡", "åˆ†ç±»", "é…æ–™"]
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™å†™å…¥è¡¨å¤´
    file_exists = False
    try:
        with open(filename, 'r') as f:
            file_exists = True
    except FileNotFoundError:
        pass

    with open(filename, mode, encoding='utf-8-sig', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=headers)
        if mode == 'w' or (mode == 'a' and not file_exists):
            writer.writeheader()
        writer.writerows(dish_list)


# 5. ä¸»æ‰§è¡Œé€»è¾‘
if __name__ == '__main__':
    print("=" * 60)
    print("      èœå“æ•°æ®åº“å…¨é‡çˆ¬å–ï¼ˆ2218é¡µï¼‰      ")
    print("=" * 60)

    driver = init_driver()
    if not driver:
        print("âŒ ç¨‹åºé€€å‡º")
        exit()

    try:
        all_dishes = crawl_all_pages(driver, start_page=1, max_page=2218, batch_size=100)
        print(f"\nğŸ“Š æœ€ç»ˆç»“æœï¼šå…±çˆ¬å–{len(all_dishes)}æ¡èœå“ä¿¡æ¯")
        print(f"ğŸ“ æ•°æ®æ–‡ä»¶ï¼šåŒ¹é…åçš„èœå“ä¿¡æ¯.csv")
    finally:
        driver.quit()
        print("\nğŸ”š æµè§ˆå™¨å·²å…³é—­")
        print("=" * 60)
